{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db81552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing All Videos: 100%|██████████| 42021/42021 [00:00<00:00, 66881.42frame/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Your dataset structure\n",
    "input_dirs = {\n",
    "    \"real\": \"Dataset/real\",\n",
    "    \"fake\": \"Dataset/fake\"\n",
    "}\n",
    "output_dir = \"ProcessedFrames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set device and load MTCNN\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(keep_all=False, device=device)\n",
    "\n",
    "# Face extraction function\n",
    "def extract_faces_from_video(video_path, output_path, sample_every_seconds=15):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Frames per second of the video\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_idx = 0\n",
    "    saved = 0\n",
    "    sample_interval = fps * sample_every_seconds  # Frames to skip to get every 15 seconds\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Extract frame every `sample_interval` frames\n",
    "        if frame_idx % sample_interval == 0:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            boxes, _ = mtcnn.detect(rgb)\n",
    "\n",
    "            if boxes is not None:\n",
    "                for box in boxes[:1]:  # Only first face per frame\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    face = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    if face.size != 0:\n",
    "                        os.makedirs(output_path, exist_ok=True)\n",
    "                        frame_name = f\"frame_{saved:03d}.jpg\"\n",
    "                        cv2.imwrite(os.path.join(output_path, frame_name), face)\n",
    "                        saved += 1\n",
    "                        break\n",
    "\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "# Count total frames for global progress bar\n",
    "total_frames_to_process = 0\n",
    "for label, folder in input_dirs.items():\n",
    "    videos = [f for f in os.listdir(folder) if f.endswith(\".mp4\")]\n",
    "    for video in videos:\n",
    "        cap = cv2.VideoCapture(os.path.join(folder, video))\n",
    "        total_frames_to_process += int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        cap.release()\n",
    "\n",
    "# Global progress bar\n",
    "with tqdm(total=total_frames_to_process, desc=\"Processing All Videos\", unit=\"frame\") as pbar:\n",
    "    for label, folder in input_dirs.items():\n",
    "        videos = [f for f in os.listdir(folder) if f.endswith(\".mp4\")]\n",
    "\n",
    "        for video in videos:\n",
    "            video_path = os.path.join(folder, video)\n",
    "            vid_name = os.path.splitext(video)[0]\n",
    "            save_folder = os.path.join(output_dir, label, vid_name)\n",
    "\n",
    "            # Skip if already processed\n",
    "            if os.path.exists(save_folder) and len(os.listdir(save_folder)) >= 1:\n",
    "                pbar.update(int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "                continue\n",
    "\n",
    "            # Extract faces\n",
    "            extract_faces_from_video(video_path, save_folder, sample_every_seconds=15)\n",
    "            pbar.update(int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fac9bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 01__hugging_happy has 3 frames.\n",
      "Video 04__talking_against_wall has 3 frames.\n",
      "Video 06__hugging_happy has 3 frames.\n",
      "Video 02__walking_outside_cafe_disgusted has 2 frames.\n",
      "Video 06__walk_down_hall_angry has 2 frames.\n",
      "Video 10__walking_outside_cafe_disgusted has 3 frames.\n",
      "Video 02__hugging_happy has 3 frames.\n",
      "Video 01__kitchen_pan has 2 frames.\n",
      "Video 01__meeting_serious has 3 frames.\n",
      "Video 09__podium_speech_happy has 3 frames.\n",
      "Video 11__outside_talking_still_laughing has 3 frames.\n",
      "Video 11__talking_angry_couch has 5 frames.\n",
      "Video 10__kitchen_pan has 2 frames.\n",
      "Video 02__outside_talking_still_laughing has 3 frames.\n",
      "Video 08__walking_outside_cafe_disgusted has 2 frames.\n",
      "Video 01__walking_and_outside_surprised has 4 frames.\n",
      "Video 07__walking_down_street_outside_angry has 3 frames.\n",
      "Video 01__exit_phone_room has 1 frames.\n",
      "Video 05__outside_talking_pan_laughing has 2 frames.\n",
      "Video 03__secret_conversation has 1 frames.\n",
      "Video 01__podium_speech_happy has 3 frames.\n",
      "Video 04__outside_talking_pan_laughing has 2 frames.\n",
      "Video 02__talking_angry_couch has 4 frames.\n",
      "Video 03__meeting_serious has 3 frames.\n",
      "Video 03__walk_down_hall_angry has 2 frames.\n",
      "Video 02_07__kitchen_pan__O4SXNLRL has 1 frames.\n",
      "Video 01_11__meeting_serious__FCNL2OVP has 3 frames.\n",
      "Video 01_02__walking_down_indoor_hall_disgust__YVGY8LOK has 3 frames.\n",
      "Video 01_15__walking_and_outside_surprised__02HILKYO has 3 frames.\n",
      "Video 01_04__podium_speech_happy__6I623VU9 has 3 frames.\n",
      "Video 02_09__walking_down_street_outside_angry__9TDCEK1Q has 2 frames.\n",
      "Video 02_04__podium_speech_happy__8CH7R4LW has 3 frames.\n",
      "Video 01_14__walking_outside_cafe_disgusted__01YF7VQM has 1 frames.\n",
      "Video 02_01__hugging_happy__YVGY8LOK has 2 frames.\n",
      "Video 01_03__talking_angry_couch__ISF9SP4G has 5 frames.\n",
      "Video 01_21__talking_angry_couch__03X7CELV has 5 frames.\n",
      "Video 02_06__walking_down_indoor_hall_disgust__SU4OQCS9 has 3 frames.\n",
      "Video 01_11__kitchen_pan__WIZ7GKOD has 2 frames.\n",
      "Video 02_12__podium_speech_happy__9D2ZHEKW has 3 frames.\n",
      "Video 01_20__talking_angry_couch__6UBMLXK3 has 5 frames.\n",
      "Video 02_06__meeting_serious__0M6JNS5D has 3 frames.\n",
      "Video 02_06__talking_angry_couch__J1W9R0NG has 4 frames.\n",
      "Video 02_09__hugging_happy__9TDCEK1Q has 2 frames.\n",
      "Video 01_27__meeting_serious__ZYCZ30C0 has 3 frames.\n",
      "Video 01_11__talking_against_wall__WIZ7GKOD has 3 frames.\n",
      "Video 01_09__secret_conversation__SJZRV69J has 1 frames.\n",
      "Video 02_07__podium_speech_happy__0IYV5DQ5 has 3 frames.\n",
      "Video 02_09__meeting_serious__6KUOFMZW has 3 frames.\n",
      "Video 02_06__exit_phone_room__3J3BHSHI has 1 frames.\n",
      "Video 02_01__walking_down_indoor_hall_disgust__YVGY8LOK has 3 frames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def verify_processed_frames(processed_dir=\"ProcessedFrames\"):\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        label_dir = os.path.join(processed_dir, label)\n",
    "        for video in os.listdir(label_dir):\n",
    "            video_dir = os.path.join(label_dir, video)\n",
    "            if os.path.isdir(video_dir):\n",
    "                num_frames = len([f for f in os.listdir(video_dir) if f.endswith('.jpg')])\n",
    "                print(f\"Video {video} has {num_frames} frames.\")\n",
    "            else:\n",
    "                print(f\"Video {video} has no frames.\")\n",
    "                \n",
    "verify_processed_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18ac30f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (137, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "def preprocess_faces(processed_dir=\"ProcessedFrames\", target_size=(224, 224)):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        label_dir = os.path.join(processed_dir, label)\n",
    "        label_class = 0 if label == \"real\" else 1  # Assign label 0 for real, 1 for fake\n",
    "        \n",
    "        for video in os.listdir(label_dir):\n",
    "            video_dir = os.path.join(label_dir, video)\n",
    "            if os.path.isdir(video_dir):\n",
    "                for frame_file in os.listdir(video_dir):\n",
    "                    if frame_file.endswith('.jpg'):\n",
    "                        frame_path = os.path.join(video_dir, frame_file)\n",
    "                        # Read image, resize and normalize\n",
    "                        frame = cv2.imread(frame_path)\n",
    "                        frame = cv2.resize(frame, target_size)\n",
    "                        frame = frame.astype(\"float32\") / 255.0  # Normalize\n",
    "\n",
    "                        X.append(frame)\n",
    "                        y.append(label_class)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_faces()\n",
    "print(\"Processed data shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "730dd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_data(X_train):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\"\n",
    "    )\n",
    "    datagen.fit(X_train)\n",
    "    return datagen\n",
    "\n",
    "# Apply augmentation to the dataset\n",
    "datagen = augment_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d0a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames in the 'real' directory: 67\n",
      "Total frames in the 'fake' directory: 70\n",
      "Total frames in the dataset: 137\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the paths for the real and fake frames\n",
    "real_frames_dir = \"ProcessedFrames/real\"\n",
    "fake_frames_dir = \"ProcessedFrames/fake\"\n",
    "\n",
    "# Function to count frames in a video folder\n",
    "def count_frames_in_video_folder(video_folder_path):\n",
    "    # Count the number of frames (files with .jpg extension)\n",
    "    frames = [f for f in os.listdir(video_folder_path) if f.endswith('.jpg')]\n",
    "    return len(frames)\n",
    "\n",
    "# Function to count frames in the entire folder (real or fake)\n",
    "def count_frames_in_folder(folder_path):\n",
    "    total_frames = 0\n",
    "    # Loop through each video folder\n",
    "    for video_folder in os.listdir(folder_path):\n",
    "        video_folder_path = os.path.join(folder_path, video_folder)\n",
    "        if os.path.isdir(video_folder_path):\n",
    "            # Count frames in the current video folder\n",
    "            total_frames += count_frames_in_video_folder(video_folder_path)\n",
    "    return total_frames\n",
    "\n",
    "# Count frames in the 'real' and 'fake' directories\n",
    "real_frames = count_frames_in_folder(real_frames_dir)\n",
    "fake_frames = count_frames_in_folder(fake_frames_dir)\n",
    "\n",
    "# Calculate total frames\n",
    "total_frames = real_frames + fake_frames\n",
    "\n",
    "# Print the total frames\n",
    "print(f\"Total frames in the 'real' directory: {real_frames}\")\n",
    "print(f\"Total frames in the 'fake' directory: {fake_frames}\")\n",
    "print(f\"Total frames in the dataset: {total_frames}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
